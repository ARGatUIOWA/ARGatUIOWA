<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://argatuiowa.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://argatuiowa.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-09-27T23:17:45+00:00</updated><id>https://argatuiowa.github.io/feed.xml</id><title type="html">Algorithms Reading Group</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Yongjian Zhong presents “Can Q-learning be improved with advice?”</title><link href="https://argatuiowa.github.io/blog/2023/Yongjian/" rel="alternate" type="text/html" title="Yongjian Zhong presents “Can Q-learning be improved with advice?”"/><published>2023-11-14T08:30:00+00:00</published><updated>2023-11-14T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Yongjian</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Yongjian/"><![CDATA[<p><strong>Abstract</strong>: Despite rapid progress in theoretical reinforcement learning (RL) over the last few years, most of the known guarantees are worst-case in nature, failing to take advantage of structure that may be known a priori about a given RL problem at hand. In this paper we address the question of whether worst-case lower bounds for regret in online learning of Markov decision processes (MDPs) can be circumvented when information about the MDP, in the form of predictions about its optimal Q-value function, is given to the algorithm. We show that when the predictions about the optimal Q-value function satisfy a reasonably weak condition we call distillation, then we can improve regret bounds by replacing the set of state-action pairs with the set of state-action pairs on which the predictions are grossly inaccurate. This improvement holds for both uniform regret bounds and gap-based ones. Further, we are able to achieve this property with an algorithm that achieves sublinear regret when given arbitrary predictions (i.e., even those which are not a distillation). Our work extends a recent line of work on algorithms with predictions, which has typically focused on simple online problems such as caching and scheduling, to the more complex and general problem of reinforcement learning.</p> <p><a href="https://arxiv.org/pdf/2110.13052.pdf">Can Q-learning be improved with advice?</a></p>]]></content><author><name></name></author><category term="Q-learning"/><summary type="html"><![CDATA[Abstract: Despite rapid progress in theoretical reinforcement learning (RL) over the last few years, most of the known guarantees are worst-case in nature, failing to take advantage of structure that may be known a priori about a given RL problem at hand. In this paper we address the question of whether worst-case lower bounds for regret in online learning of Markov decision processes (MDPs) can be circumvented when information about the MDP, in the form of predictions about its optimal Q-value function, is given to the algorithm. We show that when the predictions about the optimal Q-value function satisfy a reasonably weak condition we call distillation, then we can improve regret bounds by replacing the set of state-action pairs with the set of state-action pairs on which the predictions are grossly inaccurate. This improvement holds for both uniform regret bounds and gap-based ones. Further, we are able to achieve this property with an algorithm that achieves sublinear regret when given arbitrary predictions (i.e., even those which are not a distillation). Our work extends a recent line of work on algorithms with predictions, which has typically focused on simple online problems such as caching and scheduling, to the more complex and general problem of reinforcement learning.]]></summary></entry><entry><title type="html">Joshua Sobel presents “Graph Searching with Predictions”</title><link href="https://argatuiowa.github.io/blog/2023/Josh/" rel="alternate" type="text/html" title="Joshua Sobel presents “Graph Searching with Predictions”"/><published>2023-10-17T08:30:00+00:00</published><updated>2023-10-17T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Josh</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Josh/"><![CDATA[<p><strong>Abstract</strong>: Consider an agent exploring an unknown graph in search of some goal state. As it walks around the graph, it learns the nodes and their neighbors. The agent only knows where the goal state is when it reaches it. How do we reach this goal while moving only a small distance? This problem seems hopeless, even on trees of bounded degree, unless we give the agent some help. This setting with “help” often arises in exploring large search spaces (e.g., huge game trees) where we assume access to some score/quality function for each node, which we use to guide us towards the goal. In our case, we assume the help comes in the form of distance predictions: each node v provides a prediction $f(v)$ of its distance to the goal vertex. Naturally if these predictions are correct, we can reach the goal along a shortest path. What if the predictions are unreliable and some of them are erroneous? Can we get an algorithm whose performance relates to the error of the predictions? In this work, we consider the problem on trees and give deterministic algorithms whose total movement cost is only $O(OPT +\Delta\cdot ERR)$, where $OPT$ is the distance from the start to the goal vertex, $\Delta$ the maximum degree, and the $ERR$ is the total number of vertices whose predictions are erroneous. We show this guarantee is optimal. We then consider a “planning” version of the problem where the graph and predictions are known at the beginning, so the agent can use this global information to devise a search strategy of low cost. For this planning version, we go beyond trees and give an algorithms which gets good performance on (weighted) graphs with bounded doubling dimension.</p> <p><a href="https://arxiv.org/pdf/2212.14220.pdf">Graph Searching with Predictions</a></p>]]></content><author><name></name></author><category term="exploration"/><category term="planning"/><summary type="html"><![CDATA[Abstract: Consider an agent exploring an unknown graph in search of some goal state. As it walks around the graph, it learns the nodes and their neighbors. The agent only knows where the goal state is when it reaches it. How do we reach this goal while moving only a small distance? This problem seems hopeless, even on trees of bounded degree, unless we give the agent some help. This setting with “help” often arises in exploring large search spaces (e.g., huge game trees) where we assume access to some score/quality function for each node, which we use to guide us towards the goal. In our case, we assume the help comes in the form of distance predictions: each node v provides a prediction $f(v)$ of its distance to the goal vertex. Naturally if these predictions are correct, we can reach the goal along a shortest path. What if the predictions are unreliable and some of them are erroneous? Can we get an algorithm whose performance relates to the error of the predictions? In this work, we consider the problem on trees and give deterministic algorithms whose total movement cost is only $O(OPT +\Delta\cdot ERR)$, where $OPT$ is the distance from the start to the goal vertex, $\Delta$ the maximum degree, and the $ERR$ is the total number of vertices whose predictions are erroneous. We show this guarantee is optimal. We then consider a “planning” version of the problem where the graph and predictions are known at the beginning, so the agent can use this global information to devise a search strategy of low cost. For this planning version, we go beyond trees and give an algorithms which gets good performance on (weighted) graphs with bounded doubling dimension.]]></summary></entry><entry><title type="html">Sriram Pemmaraju presents “The primal-dual method for learning augmented algorithms”</title><link href="https://argatuiowa.github.io/blog/2023/Sriram/" rel="alternate" type="text/html" title="Sriram Pemmaraju presents “The primal-dual method for learning augmented algorithms”"/><published>2023-10-10T08:30:00+00:00</published><updated>2023-10-10T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Sriram</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Sriram/"><![CDATA[<p><strong>Abstract</strong>: The extension of classical online algorithms when provided with predictions is a new and active research area. In this paper, we extend the primal-dual method for online algorithms in order to incorporate predictions that advise the online algorithm about the next action to take. We use this framework to obtain novel algorithms for a variety of online covering problems. We compare our algorithms to the cost of the true and predicted offline optimal solutions and show that these algorithms outperform any online algorithm when the prediction is accurate while maintaining good guarantees when the prediction is misleading.</p> <p><a href="https://arxiv.org/pdf/2010.11632.pdf">The primal-dual method for learning augmented algorithms</a></p>]]></content><author><name></name></author><category term="primal-dual"/><summary type="html"><![CDATA[Abstract: The extension of classical online algorithms when provided with predictions is a new and active research area. In this paper, we extend the primal-dual method for online algorithms in order to incorporate predictions that advise the online algorithm about the next action to take. We use this framework to obtain novel algorithms for a variety of online covering problems. We compare our algorithms to the cost of the true and predicted offline optimal solutions and show that these algorithms outperform any online algorithm when the prediction is accurate while maintaining good guarantees when the prediction is misleading.]]></summary></entry><entry><title type="html">Hongyan Ji presents “Learning-Augmented Algorithms for Online Steiner Tree”</title><link href="https://argatuiowa.github.io/blog/2023/Hongyan/" rel="alternate" type="text/html" title="Hongyan Ji presents “Learning-Augmented Algorithms for Online Steiner Tree”"/><published>2023-10-03T08:30:00+00:00</published><updated>2023-10-03T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Hongyan</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Hongyan/"><![CDATA[<p><strong>Abstract</strong>: This paper considers the recently popular beyond-worst-case algorithm analysis model which integrates machine-learned predictions with online algorithm design. We consider the on- line Steiner tree problem in this model for both directed and undirected graphs. Steiner tree is known to have strong lower bounds in the online setting and any algorithm’s worst-case guarantee is far from desirable. This paper considers algorithms that predict which terminal arrives online. The predictions may be incorrect and the al- gorithms’ performance is parameterized by the number of in- correctly predicted terminals. These guarantees ensure that algorithms break through the online lower bounds with good predictions and the competitive ratio gracefully degrades as the prediction error grows. We then observe that the theory is predictive of what will occur empirically. We show on graphs where terminals are drawn from a distribution, the new on- line algorithms have strong performance even with modestly correct predictions.</p> <p><a href="https://arxiv.org/pdf/2112.05353.pdf">Learning-Augmented Algorithms for Online Steiner Tree</a></p>]]></content><author><name></name></author><category term="online"/><category term="steiner-tree"/><summary type="html"><![CDATA[Abstract: This paper considers the recently popular beyond-worst-case algorithm analysis model which integrates machine-learned predictions with online algorithm design. We consider the on- line Steiner tree problem in this model for both directed and undirected graphs. Steiner tree is known to have strong lower bounds in the online setting and any algorithm’s worst-case guarantee is far from desirable. This paper considers algorithms that predict which terminal arrives online. The predictions may be incorrect and the al- gorithms’ performance is parameterized by the number of in- correctly predicted terminals. These guarantees ensure that algorithms break through the online lower bounds with good predictions and the competitive ratio gracefully degrades as the prediction error grows. We then observe that the theory is predictive of what will occur empirically. We show on graphs where terminals are drawn from a distribution, the new on- line algorithms have strong performance even with modestly correct predictions.]]></summary></entry><entry><title type="html">Sourya Roy presents “(Learned) Frequency Estimation Algorithms under Zipfian Distribution”</title><link href="https://argatuiowa.github.io/blog/2023/Sourya/" rel="alternate" type="text/html" title="Sourya Roy presents “(Learned) Frequency Estimation Algorithms under Zipfian Distribution”"/><published>2023-09-26T08:30:00+00:00</published><updated>2023-09-26T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Sourya</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Sourya/"><![CDATA[<p><strong>Abstract</strong>: The frequencies of the elements in a data stream are an important statistical measure and the task of estimating them arises in many applications within data analysis and machine learning. Two of the most popular algorithms for this problem, Count-Min and Count-Sketch, are widely used in practice. In a recent work [Hsu et al., ICLR’19], it was shown empirically that augmenting Count- Min and Count-Sketch with a machine learning algorithm leads to a significant reduction of the estimation error. The experiments were complemented with an analysis of the expected error incurred by Count-Min (both the standard and the augmented version) when the input frequencies follow a Zipfian distribution. Although the authors established that the learned version of Count-Min has lower estimation error than its standard counterpart, their analysis of the standard Count-Min algorithm was not tight. Moreover, they provided no similar analysis for Count-Sketch. In this paper we resolve these problems. First, we provide a simple tight analysis of the expected error incurred by Count-Min. Second, we provide the first error bounds for both the standard and the augmented version of Count-Sketch. These bounds are nearly tight and again demonstrate an improved performance of the learned version of Count-Sketch. In addition to demonstrating tight gaps between the aforementioned algorithms, we believe that our bounds for the standard versions of Count-Min and Count-Sketch are of independent interest. In particular, it is a typical practice to set the number of hash functions in those algorithms to $\theta(\log n)$. In contrast, our results show that to minimize the expected error, the number of hash functions should be a constant, strictly greater than 1.</p> <p><a href="https://arxiv.org/pdf/1908.05198.pdf">(Learned) Frequency Estimation Algorithms under Zipfian Distribution</a></p>]]></content><author><name></name></author><category term="streaming-algorithms"/><summary type="html"><![CDATA[Abstract: The frequencies of the elements in a data stream are an important statistical measure and the task of estimating them arises in many applications within data analysis and machine learning. Two of the most popular algorithms for this problem, Count-Min and Count-Sketch, are widely used in practice. In a recent work [Hsu et al., ICLR’19], it was shown empirically that augmenting Count- Min and Count-Sketch with a machine learning algorithm leads to a significant reduction of the estimation error. The experiments were complemented with an analysis of the expected error incurred by Count-Min (both the standard and the augmented version) when the input frequencies follow a Zipfian distribution. Although the authors established that the learned version of Count-Min has lower estimation error than its standard counterpart, their analysis of the standard Count-Min algorithm was not tight. Moreover, they provided no similar analysis for Count-Sketch. In this paper we resolve these problems. First, we provide a simple tight analysis of the expected error incurred by Count-Min. Second, we provide the first error bounds for both the standard and the augmented version of Count-Sketch. These bounds are nearly tight and again demonstrate an improved performance of the learned version of Count-Sketch. In addition to demonstrating tight gaps between the aforementioned algorithms, we believe that our bounds for the standard versions of Count-Min and Count-Sketch are of independent interest. In particular, it is a typical practice to set the number of hash functions in those algorithms to $\theta(\log n)$. In contrast, our results show that to minimize the expected error, the number of hash functions should be a constant, strictly greater than 1.]]></summary></entry><entry><title type="html">Xiang Liu presents “Machine Learning Advised Ski Rental Problem with a Discount”</title><link href="https://argatuiowa.github.io/blog/2023/Xiang/" rel="alternate" type="text/html" title="Xiang Liu presents “Machine Learning Advised Ski Rental Problem with a Discount”"/><published>2023-09-19T08:30:00+00:00</published><updated>2023-09-19T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Xiang</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Xiang/"><![CDATA[<p><strong>Abstract</strong>: Traditional online algorithms are designed to make decisions online in the face of uncertainty to perform well in comparison with the optimal offline algorithm for the worst-case inputs. On the other hand, machine learning algorithms try to extrapolate the pattern from the past inputs to predict the future and take decisions online on basis of the predictions to perform well for the average-case inputs. There have been recent studies to augment traditional online algorithms with machine learning oracles to get better performance for all the possible inputs. The machine learning augmented online algorithms perform provably better than the traditional online algorithms when the error of the machine learning oracle is low for the worst-case inputs and all other average-case inputs. In this paper, we integrate the advantages of the traditional online algorithms and the machine learning algorithms in the context of a novel variant of the ski rental problem. Firstly, we propose the ski rental problem with a discount: in this problem, the rent of the ski, instead of being fixed over time, varies as a function of time. Secondly, we discuss the design and performance evaluation of the online algorithms with machine learning advice to solve the ski rental problem with a discount. Finally, we extend this study to the situation where multiple independent machine learning advice is available. This algorithm design framework motivates to redesign of several online algorithms by augmenting them with one or more machine learning oracles to improve the performance.</p> <p><a href="https://dl.acm.org/doi/abs/10.1007/978-3-030-96731-4_18">Machine Learning Advised Ski Rental Problem with a Discount</a></p>]]></content><author><name></name></author><category term="online"/><category term="ski-rental"/><summary type="html"><![CDATA[Abstract: Traditional online algorithms are designed to make decisions online in the face of uncertainty to perform well in comparison with the optimal offline algorithm for the worst-case inputs. On the other hand, machine learning algorithms try to extrapolate the pattern from the past inputs to predict the future and take decisions online on basis of the predictions to perform well for the average-case inputs. There have been recent studies to augment traditional online algorithms with machine learning oracles to get better performance for all the possible inputs. The machine learning augmented online algorithms perform provably better than the traditional online algorithms when the error of the machine learning oracle is low for the worst-case inputs and all other average-case inputs. In this paper, we integrate the advantages of the traditional online algorithms and the machine learning algorithms in the context of a novel variant of the ski rental problem. Firstly, we propose the ski rental problem with a discount: in this problem, the rent of the ski, instead of being fixed over time, varies as a function of time. Secondly, we discuss the design and performance evaluation of the online algorithms with machine learning advice to solve the ski rental problem with a discount. Finally, we extend this study to the situation where multiple independent machine learning advice is available. This algorithm design framework motivates to redesign of several online algorithms by augmenting them with one or more machine learning oracles to improve the performance.]]></summary></entry><entry><title type="html">Haakon Larsen presents “Improving Online Algorithms via ML Predictions”</title><link href="https://argatuiowa.github.io/blog/2023/Haakon/" rel="alternate" type="text/html" title="Haakon Larsen presents “Improving Online Algorithms via ML Predictions”"/><published>2023-09-12T08:30:00+00:00</published><updated>2023-09-12T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Haakon</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Haakon/"><![CDATA[<p><strong>Abstract</strong>: In this work we study the problem of using machine-learned predictions to improve the performance of online algorithms. We consider two classical problems, ski rental and non-clairvoyant job scheduling, and obtain new online algorithms that use predictions to make their decisions. These algorithms are oblivious to the performance of the predictor, improve with better predictions, but do not degrade much if the predictions are poor.</p> <p><a href="https://dl.acm.org/doi/pdf/10.5555/3327546.3327635">Improving Online Algorithms via ML Predictions</a></p>]]></content><author><name></name></author><category term="online"/><category term="ski-rental"/><category term="non-clairvoyant-job-scheduling"/><summary type="html"><![CDATA[Abstract: In this work we study the problem of using machine-learned predictions to improve the performance of online algorithms. We consider two classical problems, ski rental and non-clairvoyant job scheduling, and obtain new online algorithms that use predictions to make their decisions. These algorithms are oblivious to the performance of the predictor, improve with better predictions, but do not degrade much if the predictions are poor.]]></summary></entry><entry><title type="html">Bijaya Adhikari presents “Algorithms with predictions”</title><link href="https://argatuiowa.github.io/blog/2023/Bijaya/" rel="alternate" type="text/html" title="Bijaya Adhikari presents “Algorithms with predictions”"/><published>2023-09-05T08:30:00+00:00</published><updated>2023-09-05T08:30:00+00:00</updated><id>https://argatuiowa.github.io/blog/2023/Bijaya</id><content type="html" xml:base="https://argatuiowa.github.io/blog/2023/Bijaya/"><![CDATA[<p><strong>Abstract</strong>: We introduce algorithms that use predictions from machine learning applied to the input to circumvent worst-case analysis. We aim for algorithms that have near optimal performance when these predictions are good, but recover the prediction-less worst case behavior when the predictions have large errors.</p> <p><a href="http://www.cs.toronto.edu/~bor/2421s21/papers/mitzenmacher-survey.pdf">Algorithms with Predictions</a></p>]]></content><author><name></name></author><category term="online"/><category term="survey"/><summary type="html"><![CDATA[Abstract: We introduce algorithms that use predictions from machine learning applied to the input to circumvent worst-case analysis. We aim for algorithms that have near optimal performance when these predictions are good, but recover the prediction-less worst case behavior when the predictions have large errors.]]></summary></entry></feed>